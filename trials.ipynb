{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b0a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from pinecone import Pinecone\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.document_loaders import PyPDFLoader , DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f74d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the pdf file data\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"**/*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca67d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09c9563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the data\n",
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d28c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the documents into smaller chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a4fb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text chunks:  192\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Length of text chunks: \", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "206a2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dowload the embeddings model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d870c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LapMaster\\AppData\\Local\\Temp\\ipykernel_1312\\1457231952.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26d49dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f159dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b534611a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.grpc.index_grpc.GRPCIndex at 0x17456f741a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"sbot\"\n",
    "\n",
    "\n",
    "pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d439dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embed each chunk and upsert the embeddings into pinecone index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents = text_chunks,\n",
    "    embedding = embeddings,\n",
    "    index_name = index_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09f8f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing index \n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23cd635e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='bc1f1c00-8968-415c-b122-3383ea94452a', metadata={'author': 'wajahat alam', 'creationdate': '2016-08-09T14:16:47+00:00', 'creator': 'Nitro Pro 7  (7. 0. 1. 5)', 'moddate': '2016-08-09T14:17:02+00:00', 'page': 3.0, 'page_label': '4', 'producer': 'Nitro Pro 7  (7. 0. 1. 5)', 'source': 'data\\\\Fashion Course.pdf', 'title': 'Diploma in Fashion Design', 'total_pages': 46.0}, page_content='Fashion Design (Short Course)\\nP a g e 4 | 46\\nIntroduction to Fashion Design\\nClothing has long been used as more than just a way to coverpeople’s bodies. Different types of\\nclothing clearly reveal status, especially in the past but even today, and also the wearers’ personalities.\\nThis need to conceal and also to reveal relies on a range of different clothing types and will often be\\nchosen by wearers to do both. One of the most puzzling aspects of clothing is fashion.'),\n",
       " Document(id='8726e33c-7e75-4415-8f7d-08f880d2cdaf', metadata={'author': 'wajahat alam', 'creationdate': '2016-08-09T14:16:47+00:00', 'creator': 'Nitro Pro 7  (7. 0. 1. 5)', 'moddate': '2016-08-09T14:17:02+00:00', 'page': 6.0, 'page_label': '7', 'producer': 'Nitro Pro 7  (7. 0. 1. 5)', 'source': 'data\\\\Fashion Course.pdf', 'title': 'Diploma in Fashion Design', 'total_pages': 46.0}, page_content='Fashion Design (Short Course)\\nP a g e 7 | 46\\nc) Department Fashion Shows\\nDepartment fashion shows are produced in-store on a much smaller scale to generate\\nimmediate sales. A platform is usually set up right in the department itself that carries the\\nclothes.\\nd) Informal Fashion Shows\\nThe easiest shows to produce are the informal fashion shows. Models walk through the store\\nwearing the fashions and showing them to customers. Usually, customers like to ask questions'),\n",
       " Document(id='d506d60a-5f95-48ae-a997-fe6bd34ba710', metadata={'author': 'wajahat alam', 'creationdate': '2016-08-09T14:16:47+00:00', 'creator': 'Nitro Pro 7  (7. 0. 1. 5)', 'moddate': '2016-08-09T14:17:02+00:00', 'page': 7.0, 'page_label': '8', 'producer': 'Nitro Pro 7  (7. 0. 1. 5)', 'source': 'data\\\\Fashion Course.pdf', 'title': 'Diploma in Fashion Design', 'total_pages': 46.0}, page_content='\\uf0b7 Fad\\n\\uf0b7 Trends\\n\\uf0b7 Fashion Forecasting\\na) Style\\nHere is where the difference between style and fashion is clear. Style is constant and does not\\nchange but fashion always changes. Fashion is the modification of a particular style. Style is\\nconsidered to be the basic outline of any garment. Changing the s leeves or neckline, for\\nexample, and tweaking a few things here and there on a basic garment piece, changes it and')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sementic search using the embeddings\n",
    "def semantic_search(query):\n",
    "    results = docsearch.similarity_search(query, k=3)\n",
    "    return results\n",
    "\n",
    "semantic_search(\"What is Fashion?\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34e8232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a prompt template for the LLM\n",
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9446d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template2=\"\"\"\n",
    "you are an helpful assistant. You will be provided with a context and a question.\n",
    "The users are mostly students who are trying to learn about fashion, so always try to answer the question iin a way that is easy to understand.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c643afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(template=prompt_template2, \n",
    "                        input_variables=[\"context\", \"question\"])\n",
    "\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ca908c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = \"AIzaSyC4cC_Da0ovmI7-aRfQ32Pdq8Tgq6TqxJY\"\n",
    "\n",
    "#creating the LLM instance using the gemini model\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=GOOGLE_API_KEY , temperature=0.7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f655b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a74c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # Uses \"stuff\" prompt pattern\n",
    "    retriever=retriever,  # Make sure retriever is from PineconeVectorStore\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d956ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I can help with that! Based on the text you provided, here's a breakdown of the body types mentioned:\n",
      "\n",
      "*   **Triangle:** This body type is characterized by a fitted bodice (the part of a garment that covers the torso) and a bell-shaped skirt that widens gently. Think of a Spanish-style dress as an example.\n",
      "\n",
      "*   **Inverted Triangle:** This body type features wider shoulders and a narrower skirt. Dolman or raglan sleeves often accompany this shape. The text suggests this style is particularly flattering for women with larger busts.\n",
      "\n",
      "*   **Oval:** This body type involves clothing that is draped over the figure and softly shaped, creating a feminine and decorative look.\n",
      "\n",
      "I hope this helps you understand the different body types discussed in the text! Let me know if you have any other questions.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"What are the body types?\"\n",
    "response = qa.invoke({\"query\": query})\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e10e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
